{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from funk_svd.dataset import fetch_ml20m_ratings\n",
    "from funk_svd.utils import timer\n",
    "from funk_svd import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from MovieLens 20M dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MovieLens 20M Dataset Research Paper](\"http://files.grouplens.org/papers/harper-tiis2015.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Unzipping data...\n",
      "\n",
      "CPU times: user 55.6 s, sys: 5.71 s, total: 1min 1s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = fetch_ml20m_ratings()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>i_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28507</td>\n",
       "      <td>1176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1995-01-09 12:46:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131160</td>\n",
       "      <td>1079</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-01-09 12:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131160</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1995-01-09 12:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131160</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-01-09 12:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85252</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-01-29 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     u_id  i_id  rating           timestamp\n",
       "0   28507  1176     4.0 1995-01-09 12:46:44\n",
       "1  131160  1079     3.0 1995-01-09 12:46:49\n",
       "2  131160    47     5.0 1995-01-09 12:46:49\n",
       "3  131160    21     3.0 1995-01-09 12:46:49\n",
       "4   85252    45     3.0 1996-01-29 01:00:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>i_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>53930</td>\n",
       "      <td>118706</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>16978</td>\n",
       "      <td>2093</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000260</th>\n",
       "      <td>89081</td>\n",
       "      <td>55232</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:11:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>89081</td>\n",
       "      <td>52458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-03-31 08:11:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000262</th>\n",
       "      <td>87586</td>\n",
       "      <td>7151</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:40:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           u_id    i_id  rating           timestamp\n",
       "20000258  53930  118706     3.5 2015-03-31 08:00:51\n",
       "20000259  16978    2093     3.5 2015-03-31 08:03:17\n",
       "20000260  89081   55232     3.5 2015-03-31 08:11:26\n",
       "20000261  89081   52458     4.0 2015-03-31 08:11:28\n",
       "20000262  87586    7151     3.5 2015-03-31 08:40:02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a train/val/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 138,493 different users in the MovieLens20m dataset, each of them having rated at least 20 movies. Let's sample the 4 last ratings per user and randomly split them between validation and test sets. \n",
    "\n",
    "To do so, we need to query our DataFrame for each user and then select their 4 last ratings. With so much users it's naturally quite expensive... hopefully it's possible to parallelize it as iterations are independant, allowing us to save some time (especially if you have good computing ressources). I'm using an Intel Core i5-7300U CPU (only 2 physical cores) on a 16GB laptop so I won't be able to save that much :)\n",
    "\n",
    "<img src=\"https://www.dlapiper.com/~/media/images/insights/publications/2015/warning.jpg?la=en&hash=6F2E30889FD9E0B11016A1712E6E583575717C54\" width=\"23\" align=\"left\">\n",
    "\n",
    "&nbsp; If you want to run this notebook with **Windows**, you won't be able to use `multiprocessing.Pool` because it's lacking `fork()`. For simplicity you can also do it sequentially without loosing so much time compared to my dual core CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer(text=\"\")\n",
    "def compute_val_test_mask(users, df, i, n_process, n_rate=4):\n",
    "    val_test_mask = []\n",
    "    \n",
    "    for j in range(i, len(users), n_process):\n",
    "        u_id = users[j]\n",
    "        u_subset = df[df[\"u_id\"] == u_id].copy()\n",
    "        val_test_mask += u_subset.iloc[-n_rate:].index.tolist()\n",
    "        \n",
    "    print(\"Process {} done in\".format(i), end=\" \")\n",
    "    return val_test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1 done in 24 min and 44 sec\n",
      "Process 0 done in 25 min and 1 sec\n",
      "Process 3 done in 24 min and 56 sec\n",
      "Process 2 done in 25 min and 6 sec\n",
      "Process 4 done in 25 min and 4 sec\n",
      "Process 5 done in 25 min and 4 sec\n",
      "Process 7 done in 25 min and 3 sec\n",
      "Process 10 done in 24 min and 48 sec\n",
      "Process 6 done in 25 min and 8 sec\n",
      "Process 8 done in 25 min and 1 sec\n",
      "Process 9 done in 24 min and 56 sec\n",
      "Process 11 done in 24 min and 45 sec\n"
     ]
    }
   ],
   "source": [
    "users = df[\"u_id\"].unique()\n",
    "\n",
    "n_process = 12\n",
    "pool = mp.Pool(processes=n_process)\n",
    "\n",
    "results = [\n",
    "    pool.apply_async(compute_val_test_mask,\n",
    "                     args=(users, df, i, n_process))\n",
    "    for i in range(n_process)\n",
    "]\n",
    "\n",
    "results = [p.get() for p in results]\n",
    "val_test_mask = [item for sublist in results for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.drop(val_test_mask)\n",
    "val = df.loc[val_test_mask].sample(frac=0.5, random_state=7)\n",
    "test = df.loc[val_test_mask].drop(val.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | val_loss: 0.98 - val_rmse: 0.99 - val_mae: 0.78 - took 1.4 sec\n",
      "Epoch 2/100  | val_loss: 0.95 - val_rmse: 0.97 - val_mae: 0.76 - took 0.9 sec\n",
      "Epoch 3/100  | val_loss: 0.93 - val_rmse: 0.97 - val_mae: 0.76 - took 0.9 sec\n",
      "Epoch 4/100  | val_loss: 0.92 - val_rmse: 0.96 - val_mae: 0.75 - took 0.9 sec\n",
      "Epoch 5/100  | val_loss: 0.91 - val_rmse: 0.96 - val_mae: 0.75 - took 0.9 sec\n",
      "Epoch 6/100  | val_loss: 0.91 - val_rmse: 0.95 - val_mae: 0.74 - took 0.9 sec\n",
      "Epoch 7/100  | val_loss: 0.90 - val_rmse: 0.95 - val_mae: 0.74 - took 0.9 sec\n",
      "Epoch 8/100  | val_loss: 0.90 - val_rmse: 0.95 - val_mae: 0.74 - took 0.9 sec\n",
      "Epoch 9/100  | val_loss: 0.89 - val_rmse: 0.94 - val_mae: 0.73 - took 0.9 sec\n",
      "Epoch 10/100 | val_loss: 0.89 - val_rmse: 0.94 - val_mae: 0.73 - took 0.9 sec\n",
      "Epoch 11/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.73 - took 0.9 sec\n",
      "Epoch 12/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.73 - took 0.9 sec\n",
      "Epoch 13/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.73 - took 0.9 sec\n",
      "Epoch 14/100 | val_loss: 0.87 - val_rmse: 0.93 - val_mae: 0.73 - took 0.9 sec\n",
      "Epoch 15/100 | val_loss: 0.87 - val_rmse: 0.93 - val_mae: 0.72 - took 0.9 sec\n",
      "Epoch 16/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.72 - took 0.9 sec\n",
      "Epoch 17/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.72 - took 0.9 sec\n",
      "Epoch 18/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.72 - took 0.9 sec\n",
      "Epoch 19/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.72 - took 0.9 sec\n",
      "Epoch 20/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 21/100 | val_loss: 0.84 - val_rmse: 0.92 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 22/100 | val_loss: 0.84 - val_rmse: 0.92 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 23/100 | val_loss: 0.84 - val_rmse: 0.91 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 24/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 25/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 26/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 27/100 | val_loss: 0.82 - val_rmse: 0.91 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 28/100 | val_loss: 0.82 - val_rmse: 0.91 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 29/100 | val_loss: 0.82 - val_rmse: 0.90 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 30/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 31/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 32/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 33/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 34/100 | val_loss: 0.80 - val_rmse: 0.90 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 35/100 | val_loss: 0.80 - val_rmse: 0.89 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 36/100 | val_loss: 0.80 - val_rmse: 0.89 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 37/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 38/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 39/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 40/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.9 sec\n",
      "Epoch 41/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.68 - took 0.9 sec\n",
      "Epoch 42/100 | val_loss: 0.78 - val_rmse: 0.89 - val_mae: 0.68 - took 0.9 sec\n",
      "Epoch 43/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.68 - took 0.9 sec\n",
      "Epoch 44/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.68 - took 0.9 sec\n",
      "Epoch 45/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.68 - took 0.9 sec\n",
      "Epoch 46/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.68 - took 0.9 sec\n",
      "\n",
      "Training took 48 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<funk_svd.svd.SVD at 0x7f68be06dd30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(learning_rate=0.001, regularization=0.005, n_epochs=100,\n",
    "          n_factors=15, min_rating=1, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val, early_stopping=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and compute results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.88\n",
      "Test MAE:  0.68\n",
      "\n",
      "CPU times: user 750 ms, sys: 10.5 ms, total: 761 ms\n",
      "Wall time: 751 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred = svd.predict(test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test[\"rating\"], pred))\n",
    "mae = mean_absolute_error(test[\"rating\"], pred)\n",
    "\n",
    "print(\"Test RMSE: {:.2f}\".format(rmse))\n",
    "print(\"Test MAE:  {:.2f}\".format(mae))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Surprise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format data according Surprise way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 s, sys: 2.47 s, total: 37.8 s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "trainset = Dataset.load_from_df(train[[\"u_id\", \"i_id\", \"rating\"]],\n",
    "                               reader=reader).build_full_trainset()\n",
    "\n",
    "testset = Dataset.load_from_df(test[[\"u_id\", \"i_id\", \"rating\"]], reader=reader)\n",
    "testset = testset.construct_testset(testset.raw_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "\n",
      "CPU times: user 11min 13s, sys: 650 ms, total: 11min 13s\n",
      "Wall time: 11min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd = SVD(lr_all=.001, reg_all=0.005, n_epochs=46, n_factors=15, verbose=True)\n",
    "svd.fit(trainset)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and compute results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.88\n",
      "Test MAE:  0.68\n",
      "\n",
      "CPU times: user 1.92 s, sys: 290 ms, total: 2.21 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred = svd.test(testset)\n",
    "y_true = [p.r_ui for p in pred]\n",
    "y_hat = [p.est for p in pred]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_hat))\n",
    "mae = mean_absolute_error(y_true, y_hat)\n",
    "\n",
    "print(\"Test RMSE: {:.2f}\".format(rmse))\n",
    "print(\"Test MAE:  {:.2f}\".format(mae))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy performance is naturally equivalent, difference stands in the computation time, `Numba` allowing us to run more than 10 times faster than with cython.\n",
    "\n",
    "| Movielens 20M | RMSE   | MAE    | Time          |\n",
    "|:--------------|:------:|:------:|--------------:|\n",
    "| Surprise      |  0.88  |  0.68  | 11 min 13 sec |\n",
    "| Funk-svd      |  0.88  |  0.68  |        48 sec |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
